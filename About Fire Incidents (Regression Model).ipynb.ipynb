{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing models_Yang.ipynb","version":"0.3.2","provenance":[{"file_id":"1zQ8E0NjxuF873du1-QZ1um5DMvAQwB5M","timestamp":1566001958211}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HJyugyi5yMvj","colab_type":"text"},"source":["# Testing regressions models: Linear Regression, Batch Gradient Descent, Stochastic Gradient Descent, and SVM Regression"]},{"cell_type":"markdown","metadata":{"id":"6Fq7DJv-yDMS","colab_type":"text"},"source":["Workbook setup code copied from in-course examples.\n","\n","First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"]},{"cell_type":"code","metadata":{"id":"Hku0kMwbUDnK","colab_type":"code","colab":{}},"source":["# To support both python 2 and python 3\n","from __future__ import division, print_function, unicode_literals\n","\n","# Common imports\n","import numpy as np\n","import os\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(98)\n","\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# Where to save the figures\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"training_linear_models\"\n","\n","def save_fig(fig_id, tight_layout=True):\n","    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n","    print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format='png', dpi=300)\n","\n","# Ignore useless warnings (see SciPy issue #5998)\n","import warnings\n","warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MWA_3tfEyrkL","colab_type":"text"},"source":["# Import data"]},{"cell_type":"code","metadata":{"id":"f_QlIyiJywqY","colab_type":"code","colab":{}},"source":["#code to authorize access to Google Drive\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSgkXt0N4S5-","colab_type":"code","colab":{}},"source":["import gspread\n","from oauth2client.client import GoogleCredentials\n","\n","gc = gspread.authorize(GoogleCredentials.get_application_default())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sk6GwewY6cpK","colab_type":"code","colab":{}},"source":["#code to impport data\n","#worksheet = gc.open('Dummy data_reduced').sheet1\n","\n","worksheet = gc.open('FData_explored_full').sheet1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fqs5h0U6yzMV","colab_type":"text"},"source":["# Create data frame from imported data"]},{"cell_type":"code","metadata":{"id":"P-qGKc5hDvWZ","colab_type":"code","colab":{}},"source":["# Read contents of CSV file\n","df_rows = worksheet.get_all_values()\n","\n","# Convert to a DataFrame and render.\n","import pandas as pd\n","cols = df_rows[0]\n","df  = pd.DataFrame.from_records(df_rows, columns = cols)\n","\n","#drop the duplicate header row\n","df = df.reindex(df.index.drop(0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYmPWd4pKaK2","colab_type":"code","colab":{}},"source":["#set target variable column name\n","target = df_rows[0][0]\n","#set column names of all features\n","features = df_rows[0][1:]\n","\n","import numpy as np\n","\n","# Prepare the data\n","X = np.c_[df[features]]\n","y = np.c_[df[target]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8Rr4kT84L_O","colab_type":"code","colab":{}},"source":["X=X.astype(float)\n","y=y.astype(float)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnggGQU5tDvT","colab_type":"text"},"source":["Data comes in as mixed categorical and numerical values. Need to tell the dataframe that. If not, everything comes in as object datatype, which makes processing difficult later"]},{"cell_type":"code","metadata":{"id":"6KieByz7tDZq","colab_type":"code","colab":{}},"source":["#from sklearn.pipeline import Pipeline\n","#from sklearn.compose import ColumnTransformer\n","#from sklearn.impute import SimpleImputer\n","#from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","#create the preprocessing pipeline for both numeric and categorical data.\n","#numeric_features = ['Eng_Response_time (minutes)', \n","#                    'Eng_Fire_Under_Control_Time (minutes)', \n","#                    'Eng_Last_TFS_Unit_Clear_Time (minutes)']\n","#numeric_transformer = Pipeline(steps=[\n","#    ('imputer', SimpleImputer(strategy='median')),\n","#    ('scaler', StandardScaler())])\n","\n","#categorical_features = ['Extent_Of_Fire', 'Fire_Alarm_System_Operation', \n","#                        'Incident_Ward', 'Method_Of_Fire_Control', \n","#                        'Possible_Cause', 'Property_Use', \n","#                        'Smoke_Alarm_at_Fire_Origin', \n","#                        'Sprinkler_System_Operation', \n","#                        'Status_of_Fire_On_Arrival']\n","#categorical_transformer = Pipeline(steps=[\n","#    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","#    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","\n","#preprocessor = ColumnTransformer(\n","#    transformers=[\n","#        ('num', numeric_transformer, numeric_features),\n","#        ('cat', categorical_transformer, categorical_features)])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bu2AtIhn-o96","colab_type":"text"},"source":["Split dataset into training and test data"]},{"cell_type":"code","metadata":{"id":"wNqhoP4CRMxa","colab_type":"code","outputId":"d5d40de1-78f3-4e05-bc0d-2b74bfb7b4eb","executionInfo":{"status":"ok","timestamp":1566354076196,"user_tz":240,"elapsed":888,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#split dataset into 80/20 dataset\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2)\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5900, 90), (1476, 90), (5900, 1), (1476, 1))"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"FXTBanxzpj7I","colab_type":"text"},"source":["# Normalize data"]},{"cell_type":"code","metadata":{"id":"Hc91CsH3pji7","colab_type":"code","colab":{}},"source":["#from sklearn.preprocessing import StandardScaler\n","# Define Scaling technique\n","#scaler = StandardScaler()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AX7So9ARpo_2","colab_type":"code","colab":{}},"source":["# Train escaling object \n","#X_train_escaler = scaler.fit(X_train)\n","\n","# Apply scaling model to the data\n","#X_train_escaled = X_train_escaler.transform(X_train)\n","#X_train_escaled"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRg0q5bUKZbh","colab_type":"text"},"source":["# Test Linear Regression model"]},{"cell_type":"code","metadata":{"id":"2zJ7vxLsy5bC","colab_type":"code","outputId":"6d241c5a-7b93-49d3-b3f6-6586d607ad1d","executionInfo":{"status":"ok","timestamp":1566354428133,"user_tz":240,"elapsed":326,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"source":["#import sklearn linear regression model\n","from sklearn.linear_model import LinearRegression\n","lr = LinearRegression()\n","\n","lr.fit(X_train, y_train)\n","lr.intercept_, lr.coef_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([5.30230897e+09]),\n"," array([[-6.85965784e+02, -6.85837906e+02, -6.85886226e+02,\n","         -6.85951955e+02, -6.85964706e+02, -6.85868840e+02,\n","         -6.85972312e+02, -6.85918784e+02, -6.85924026e+02,\n","         -6.85963501e+02, -6.85924500e+02, -6.85930398e+02,\n","         -6.85790147e+02, -6.85908528e+02, -6.86071945e+02,\n","         -6.85908424e+02, -6.85900867e+02, -6.85989240e+02,\n","         -6.86092920e+02, -6.86113537e+02, -6.85971752e+02,\n","         -6.86040577e+02, -6.86105879e+02, -6.85878310e+02,\n","         -6.85788798e+02, -6.85877550e+02, -6.86017409e+02,\n","         -6.86074981e+02, -6.86061140e+02, -6.86098668e+02,\n","         -6.86091068e+02, -6.86031757e+02, -6.85972473e+02,\n","         -6.85930235e+02, -6.85893803e+02, -6.85866535e+02,\n","         -6.85949047e+02, -6.85777492e+02, -6.85790954e+02,\n","         -6.85790429e+02, -6.85861137e+02, -6.85879372e+02,\n","         -6.85872147e+02, -6.85888284e+02, -6.85914331e+02,\n","         -2.74576178e+09, -2.74576177e+09, -2.74576177e+09,\n","          1.76411087e+09,  1.76411087e+09,  1.76411087e+09,\n","          1.76411087e+09,  1.76411087e+09,  3.40171130e+08,\n","          3.40171130e+08, -3.56883709e+08, -3.56883709e+08,\n","         -3.56883709e+08, -3.56883709e+08, -3.56883709e+08,\n","         -3.45464125e+09, -3.45464125e+09, -3.45464125e+09,\n","         -3.45464125e+09, -3.45464125e+09,  9.96244380e+08,\n","          9.96244380e+08,  9.96244381e+08,  9.96244381e+08,\n","         -1.60961709e+09, -1.60961709e+09, -1.60961709e+09,\n","         -1.60961709e+09, -1.60961709e+09, -1.60961709e+09,\n","         -1.60961709e+09, -1.60961709e+09, -1.60961709e+09,\n","         -1.60961709e+09, -1.60961709e+09, -1.60961709e+09,\n","         -2.35930833e+08, -2.35930833e+08, -2.35930833e+08,\n","         -2.35930833e+08, -2.35930833e+08, -2.35930833e+08,\n","          1.54125481e-02,  1.47364628e-03,  1.31113212e-03]]))"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"rST0XaP9TSkf","colab_type":"code","outputId":"c549e71a-26ba-4875-8a73-11687feff949","executionInfo":{"status":"ok","timestamp":1566354431169,"user_tz":240,"elapsed":401,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["lr.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.31601942037496766"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"9kc-DvMKzJ06","colab_type":"text"},"source":["# Test Batch Gradient Descent model"]},{"cell_type":"code","metadata":{"id":"lR8xDdHp6jQE","colab_type":"code","colab":{}},"source":["eta = 0.1\n","n_iterations = 1000\n","m = len(X_train)\n","theta = np.random.randn(len(X_train[0]),1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LpsEaQHHzPUJ","colab_type":"code","outputId":"b4a9a298-6eee-4cec-dec2-963bc04a728e","executionInfo":{"status":"ok","timestamp":1566354441077,"user_tz":240,"elapsed":935,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for iteration in range(n_iterations):\n","    gradients = 2/m * X_train.T.dot(X_train.dot(theta) - y_train)\n","    theta = theta - eta * gradients"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in subtract\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"R5tepEkY5lxp","colab_type":"code","colab":{}},"source":["theta"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rday5jzezM9I","colab_type":"text"},"source":["# Test Stochastic Gradient Descent model"]},{"cell_type":"code","metadata":{"id":"vYeUEp-PrZVB","colab_type":"code","colab":{}},"source":["theta_path_sgd = []\n","m = len(X_train)\n","np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rs_Bk3jureS1","colab_type":"code","outputId":"1d4d1fab-727c-45cc-e657-d564426ac49c","executionInfo":{"status":"ok","timestamp":1566354849217,"user_tz":240,"elapsed":3636,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["n_epochs = 50\n","t0, t1 = 5, 50  # learning schedule hyperparameters\n","\n","def learning_schedule(t):\n","    return t0 / (t + t1)\n","\n","theta = np.random.randn(len(X_train[0]),1)  # random initialization\n","\n","for epoch in range(n_epochs):\n","    for i in range(m):\n","        random_index = np.random.randint(m)\n","        xi = X_train[random_index:random_index+1]\n","        yi = y_train[random_index:random_index+1]\n","        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n","        eta = learning_schedule(epoch * m + i)\n","        theta = theta - eta * gradients\n","        theta_path_sgd.append(theta)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in multiply\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in subtract\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k6tmtuEdBlnw","colab_type":"code","colab":{}},"source":["theta"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JdhlVJWkwguW","colab_type":"text"},"source":["# Test Support Vector Machines"]},{"cell_type":"code","metadata":{"id":"kYVResaHsLtO","colab_type":"code","outputId":"e72dce82-86b2-4f9a-cea1-aec6cff890cc","executionInfo":{"status":"ok","timestamp":1566354902811,"user_tz":240,"elapsed":745,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["from sklearn.svm import LinearSVR\n","\n","svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n","svm_reg.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LinearSVR(C=1.0, dual=True, epsilon=1.5, fit_intercept=True,\n","          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n","          random_state=42, tol=0.0001, verbose=0)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"vn49SLjEx1cG","colab_type":"code","outputId":"6c305cc0-67d6-4495-df18-c8ed8c0b41a8","executionInfo":{"status":"ok","timestamp":1566354905404,"user_tz":240,"elapsed":366,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["svm_reg.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.14401759067097286"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"S7JnNJde0iWG","colab_type":"text"},"source":["# Tune SVM regression hyperparameters"]},{"cell_type":"code","metadata":{"id":"aFf6i5pb0mV1","colab_type":"code","outputId":"9d547eb7-bc1e-4bc9-ca5a-f0a202756c36","executionInfo":{"status":"ok","timestamp":1566355209134,"user_tz":240,"elapsed":726,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["svm_reg2 = LinearSVR(epsilon=1.3, random_state=42)\n","svm_reg2.fit(X_train, y_train)\n","svm_reg2.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.17673933316195578"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"YU0hQnUDC-XZ","colab_type":"code","outputId":"bd20c589-9922-41d8-db11-236e01686574","executionInfo":{"status":"ok","timestamp":1566355244070,"user_tz":240,"elapsed":852,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["svm_reg3 = LinearSVR(epsilon=1.1, random_state=42)\n","svm_reg3.fit(X_train, y_train)\n","svm_reg3.score(X_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.1535655471989784"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"Z0_D6EAtEALo","colab_type":"text"},"source":["# Conclusion\n","\n","Regression models seemed to perform poorly on this dataset.\n","\n","- Target variable actually behaves more like categories despite having numerical values. I.e. dollar amounts are typically rounded to the nearest thousand, ten thousand, hundred thousand etc.\n","- Too many categorical features. We did not do enough exploration to estimate the potential predicting power of these features. We likely did not choose useful features to keep.\n","- Features were not scaled. Did not figure out how to scale only some of the numerical features while leaving the categorical features alone.\n","- Did not try non-linear regression. Already too many features so were concerned with computational cost. Also did not have time to try it."]}]}